#!/usr/bin/env python3

import argparse
import json
import os
import sys
import statistics  # Add this to imports at the top

sys.path.append(os.path.join(
    os.path.dirname(os.path.abspath(__file__)), "..", "lib"))
from common import json_load


#
# Global
#

CEPH_DIAGNOSTICS_COLLECT_DIR = os.environ.get('CEPH_DIAGNOSTICS_COLLECT_DIR')

cmd_description="process pg dump"
epilog="""
Commands:
  ls-by-osd <id|osd.id>      - list pg on osd [osd]
  ls-by-primary <id|osd.id>  - list pg with primary = [osd]
  info <pgid>                - show pg info
  stats <pgid>               - show pg stats
  scrub-stats                - show scrub stats
  check-pg-on-same-host      - check if pgs are on the same host"""

parser = argparse.ArgumentParser(prog='cds osd',
                                 description=cmd_description,
                                 epilog=epilog,
                                 formatter_class=argparse.RawTextHelpFormatter)
parser.add_argument(
    'command',
    metavar='ls-by-osd|ls-by-primary|info|stats|scrub-stats|check-pg-on-same-host',
    help='command',
    nargs=1,
    default=None,
)
parser.add_argument(
    'id',
    metavar='id',
    help='osd or pg id',
    nargs='*',
    default=None,
)

#
# Functions
#

def description():
    print(cmd_description)

def help():
    parser.print_help()

def get_osd_id(name):
    if name.startswith('osd.'):
        name = name[4:]
    return int(name)

def get_pg_dump():
    return json_load(
        os.path.join(CEPH_DIAGNOSTICS_COLLECT_DIR, "pg_info-dump_json")
    )

def get_osd_metadata():
    return json_load(
        os.path.join(CEPH_DIAGNOSTICS_COLLECT_DIR, "osd_info-metadata")
    )

def ls_by_osd(osd_ids):
    pg_dump = get_pg_dump()
    for osd_id in osd_ids:
        osd_id = get_osd_id(osd_id)
        pgs = [pg['pgid'] for pg in pg_dump['pg_map']['pg_stats'] \
               if osd_id in pg['acting'] or osd_id in pg['up']]
        with open(CEPH_DIAGNOSTICS_COLLECT_DIR + "/pg_info-dump", "r") as f:
            for line in f.readlines():
                cols = line.strip().split()
                if cols and cols[0] in pgs:
                    print(line.strip())

def ls_by_primary(osd_ids):
    pg_dump = get_pg_dump()
    for osd_id in osd_ids:
        osd_id = get_osd_id(osd_id)
        pgs = [pg['pgid'] for pg in pg_dump['pg_map']['pg_stats'] \
               if osd_id == pg['acting_primary'] or osd_id == pg['up_primary']]
        with open(CEPH_DIAGNOSTICS_COLLECT_DIR + "/pg_info-dump", "r") as f:
            for line in f.readlines():
                cols = line.strip().split()
                if cols and cols[0] in pgs:
                    print(line.strip())

def info(pgids):
    pg_dump = get_pg_dump()
    for pg in pg_dump['pg_map']['pg_stats']:
        if pg['pgid'] in pgids:
            print("pgid:      ", pg['pgid'])
            print("state:     ", pg['state'])
            print("up:        ", pg['up'])
            print("acting:    ", pg['acting'])
            print("objects:   ", pg['stat_sum']['num_objects'])
            print("bytes:     ", pg['stat_sum']['num_bytes'])
            print("omap_keys: ", pg['stat_sum']['num_omap_keys'])
            print("omap_bytes:", pg['stat_sum']['num_omap_bytes'])
            print("unfound:   ", pg['stat_sum']['num_objects_unfound'])
            print("snaptrimq: ", pg['snaptrimq_len'])
            print("scrub:     ", pg['last_scrub_stamp'])
            print("deep-scrub:", pg['last_deep_scrub_stamp'],
                  "(", pg['last_scrub_duration'], "sec)")

def stats(pgids):
    pg_dump = get_pg_dump()
    for pg in pg_dump['pg_map']['pg_stats']:
        if pg['pgid'] in pgids:
            print(json.dumps(pg, indent=2))

def scrub_stats():
    pg_dump = get_pg_dump()
    scrub_duration_sum = 0
    scrub_durations = []  # for overall stats
    max_scrub_duration = 0
    min_scrub_duration = float('inf')
    num_objects_sum = 0
    num_bytes_sum = 0
    scrub_duration_sum_pool = {}
    num_objects_sum_pool = {}
    num_bytes_sum_pool = {}
    num = {}
    # New: dictionary to store durations per pool
    pool_durations = {}

    for pg in pg_dump['pg_map']['pg_stats']:
        if 'scrub_duration' in pg:
            duration = pg['scrub_duration']
            scrub_duration_sum += duration
            scrub_durations.append(duration)
            num_objects_sum += pg['stat_sum']['num_objects']
            num_bytes_sum += pg['stat_sum']['num_bytes']
            pool = pg['pgid'].split('.')[0]

            # Initialize pool lists if not exists
            if pool not in pool_durations:
                pool_durations[pool] = []
            pool_durations[pool].append(duration)

            num[pool] = num.get(pool, 0) + 1
            scrub_duration_sum_pool[pool] = scrub_duration_sum_pool.get(pool, 0) + duration
            num_objects_sum_pool[pool] = num_objects_sum_pool.get(pool, 0) + pg['stat_sum']['num_objects']
            num_bytes_sum_pool[pool] = num_bytes_sum_pool.get(pool, 0) + pg['stat_sum']['num_bytes']

    print("total number of pgs: %d" % len(pg_dump['pg_map']['pg_stats']))
    print("total scrub duration: %d sec" % scrub_duration_sum)
    print("average scrub duration: %d sec" % (scrub_duration_sum / len(pg_dump['pg_map']['pg_stats'])))
    print("total number of objects: %d" % num_objects_sum)
    print("average number of objects per pg: %d" % (num_objects_sum / len(pg_dump['pg_map']['pg_stats'])))
    print("total size: %d bytes" % num_bytes_sum)
    print("average pg size: %d bytes" % (num_bytes_sum / len(pg_dump['pg_map']['pg_stats'])))
    print("per pool scrub duration:")
    for pool in num:
        pool_std_dev = 0.0
        if len(pool_durations[pool]) > 1:  # Need at least 2 values for std dev
            pool_std_dev = statistics.stdev(pool_durations[pool])

        print("  %s: %d sec (%d pgs, %d sec/pg, %d bytes/pg, %d obj/pg, %.2f sec std_dev)" %
              (pool, scrub_duration_sum_pool[pool], num[pool],
               scrub_duration_sum_pool[pool] / num[pool],
               num_bytes_sum_pool[pool] / num[pool],
               num_objects_sum_pool[pool] / num[pool],
               pool_std_dev))

def check_pg_on_same_host():
    osd_metadata = get_osd_metadata()
    pg_dump = get_pg_dump()

    osds = {o['id'] : o['hostname'] for o in osd_metadata}

    exit_code = 0
    for pg in pg_dump['pg_map']['pg_stats']:
        hosts = {}
        for osd_id in pg['up']:
            h = osds[osd_id]
            if h in hosts:
                print(f"{pg['pgid']}: osd.{osd_id} and osd.{hosts[h]} are on the same host {h}")
                exit_code += 1
            else:
                hosts[h] = osd_id

    exit(exit_code)

def main():
    if len(sys.argv) > 1:
        if sys.argv[1] == 'description':
            description()
            exit(0)
        elif sys.argv[1] == 'help':
            help()
            exit(0)

    args = parser.parse_args()

    if 'check-pg-on-same-host' in args.command:
        check_pg_on_same_host()
    elif 'ls-by-osd' in args.command:
        ls_by_osd(args.id)
    elif 'ls-by-primary' in args.command:
        ls_by_primary(args.id)
    elif 'info' in args.command:
        info(args.id)
    elif 'stats' in args.command:
        stats(args.id)
    elif 'scrub-stats' in args.command:
        scrub_stats()
    else:
        print('invalid command: {}'.format(args.command), file=sys.stderr)
        print('', file=sys.stderr)
        parser.print_help()
        exit(1)

#
# main
#

main()
